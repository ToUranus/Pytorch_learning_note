{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量\n",
    "+ 张量和数组、矩阵一样，是一种特殊的数据结构，在pytorch中，神经网络的输入、输出以及网络参数都是用张量进行描述的。\n",
    "+ 张量和np.ndarrays很类似，区别在于张量可以在GPU或者其他专用硬件熵运行，获得加速效果。\n",
    "### 张量初始化效果\n",
    "1. 直接生成：`torch.tensor([1,2])`\n",
    "2. numpy生成：`x_np = torch.from_numpy(np_array)`，反过来，使用张量生成numpy数组也可。（即可以相互转换)\n",
    "3. 通过已有张量生成，新的张量继承已有张量的数据属性（结构、类型），也可以重新指定：`x_ones = torch.ones_like(x_data)`、`x_rand = torch.randd_like(x_data,dtype=torch.float)`\n",
    "4. 指定数据维度来生成张量（实例见下一个cell）。\n",
    "   \n",
    "### 张量属性\n",
    "+ 从张量属性可以得到张量的维数、数据类型以及他们所存储的设备（CPU或者GPU）\n",
    "  \n",
    "### 张量运算\n",
    "+ 有超过100种的张量运算方式，例如转置、索引、切片、数学运算、线性代数、随机采样等。\n",
    "+ 所有这些运算都可以在GPU上运行。判断当前环境GPU是否可用：`if torch.cuda.is_available()：tensor = tensor.to('cuda)`\n",
    "\n",
    "### 张量与numpy之间转化\n",
    "+ 张量和numpy array数组在cpu上可以共用一块内存区域，改变其中一个，另一个也会随之改变。\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor:\n",
      " tensor([[0.7225, 0.1703, 0.0274],\n",
      "        [0.5735, 0.0462, 0.3702]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 指定数据维度来生成张量\n",
    "shape = (2,3,) # 元组\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f'Random Tensor:\\n {rand_tensor} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "t1: tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "逐个元素相乘结果：tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "\n",
      "逐个元素相乘等价写法结果：tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "\n",
      "矩阵乘法，tensor乘以tensor的转置：tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "\n",
      "矩阵乘法的等价写法结果：tensor([[3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 张量的运算\n",
    "\n",
    "# 索引和切片\n",
    "tensor = torch.ones(4,4)\n",
    "tensor[:,1] = 0\n",
    "print('tensor:',tensor)\n",
    "\n",
    "# 张量拼接:torch.cat()、torch.stack()等\n",
    "t1 = torch.cat([tensor,tensor,tensor],dim=1)\n",
    "print('t1:',t1)\n",
    "\n",
    "# 张量的乘积和矩阵乘法\n",
    "mul_1 = tensor.mul(tensor)\n",
    "print(f'逐个元素相乘结果：{mul_1}\\n')\n",
    "mul_2 = tensor*tensor\n",
    "print(f'逐个元素相乘等价写法结果：{mul_2}\\n')\n",
    "\n",
    "mul_3 = tensor.matmul(tensor.T)\n",
    "print(f'矩阵乘法，tensor乘以tensor的转置：{mul_3}\\n')\n",
    "mul_4 = tensor @ tensor\n",
    "print(f'矩阵乘法的等价写法结果：{mul_4}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# 自动赋值运算\n",
    "# 自动赋值运算通常在方法后有_作为后缀，\n",
    "# 例如：x.copy_(y)操作会改变x的取值\n",
    "\n",
    "print(tensor,'\\n')\n",
    "tensor.add_(5)\n",
    "print(tensor)\n",
    "\n",
    "# 注意：自动赋值运算虽然可以节省内存，但是在求导的过程中由于丢失了中间过程而导致一些问题，不鼓励使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张量t:tensor([1., 1., 1., 1., 1.])\n",
      "\n",
      "array n:[1. 1. 1. 1. 1.]\n",
      "\n",
      "tensor([100.,   1.,   1.,   1.,   1.])\n",
      "[100.   1.   1.   1.   1.]\n",
      "array m:[1. 1. 1. 1. 1.]\n",
      "\n",
      "张量t_m:tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "\n",
      "[ 1.  1. 99.  1.  1.]\n",
      "tensor([ 1.,  1., 99.,  1.,  1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 张量转为numpy array\n",
    "t = torch.ones(5)\n",
    "print(f'张量t:{t}\\n')\n",
    "n = t.numpy()\n",
    "print(f'array n:{n}\\n')\n",
    "\n",
    "# 修改张量的值，则array的值也随之改变。（最前面的概念，它俩可以用一块内存在cpu上）\n",
    "t[0] = 100\n",
    "print(t)\n",
    "print(n)\n",
    "\n",
    "# 由array 转化为tensor\n",
    "m = np.ones(5)\n",
    "print(f'array m:{m}\\n')\n",
    "t_m = torch.from_numpy(m)\n",
    "print(f'张量t_m:{t_m}\\n')\n",
    "\n",
    "# 修改数组的值，张量的值也会随之改变\n",
    "m[2] = 99\n",
    "print(m)\n",
    "print(t_m)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
